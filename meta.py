# -*- coding: utf-8 -*-
"""Final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13bVNJQT4brpNp3zmVr42NU45ENbatgh5

Disease Prediction from metagenomic data
"""

#Load cirhossis feature dataset

import pandas as pd
df = pd.read_csv("/content/Cirrhosis_x_filtered.csv")
df.set_index('sampleID',inplace=True)
df

# Transpose feature dataset

df_t = df.transpose() # transpose data
df_t

#load cirrhosis label dataset
df2 = pd.read_csv("/content/Cirrhosis_y.csv")
df2.set_index('sampleID',inplace=True)
df2

# merge features and label into one dataframe
df_merge = df_t.join(df2)
df_merge

#statistics of each column in data
df_merge.describe()

df_merge.info()

# check if there is any missing data
df_merge[(df_merge.isna().any(axis=1))]

#Visualize distribution of variables using boxplot.

import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
boxplot = df_merge.boxplot(patch_artist=True, meanline=True, showmeans=True)
plt.xticks(rotation = 45)
plt.xlabel('Feature Variables')
plt.ylabel('Values')
plt.title('Distribution of Features')
plt.show()

# split into train and test datasets
from sklearn.model_selection import train_test_split

features = df_merge.drop(columns='disease')
labels = pd.DataFrame(df_merge['disease'])
X_train, X_test, y_train, y_test = train_test_split(
    features, labels, test_size=0.2, random_state=23)
X_train.shape

y_train.shape

# data normalization

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train) # transform training data
X_test = scaler.transform(X_test) # transform testing data
X_train_scaled = pd.DataFrame(X_train, columns=features.columns)
X_train_scaled

#2. Visualize distribution of variables using boxplot after normalization.

plt.figure(figsize=(20,10))
boxplot = X_train_scaled.boxplot(patch_artist=True, meanline=True, showmeans=True)
plt.xticks(rotation = 45)
plt.xlabel('Feature Variables')
plt.ylabel('Values')
plt.title('Distribution of Features')
plt.show()

"""PCA Analysis"""

# Get the information about the explained variance and plot the cumulative variance

from sklearn.decomposition import PCA
import numpy as np

pca = PCA().fit(X_train)

import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (12,6)

fig, ax = plt.subplots()
xi = np.arange(1, 13, step=1)
y = np.cumsum(pca.explained_variance_ratio_)

plt.ylim(0.0,1.1)
plt.plot(xi, y, marker='o', linestyle='--', color='b')

plt.xlabel('Number of Components')
plt.xticks(np.arange(0, 100, step=10)) #change from 0-based array index to 1-based human-readable label
plt.ylabel('Cumulative variance (%)')
plt.title('The number of components needed to explain variance')

plt.axhline(y=0.95, color='r', linestyle='-')
plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)

ax.grid(axis='x')
plt.show()

"""In this case, to get 95% of variance explained I need 10 principal components."""

# Applying clustering analysis on the feature data to discover the patterns among samples

import numpy as np
from sklearn.cluster import KMeans

kmeans_model = KMeans(init='k-means++')
kmeans_model.fit(X_train)
train_cluster_labels  = kmeans_model.predict(X_train)
train_cluster_labels

from sklearn.decomposition import PCA

pca = PCA(n_components=10)
pca.fit(X_train)
pca_data = pca.transform(X_train)
print("original shape:   ", X_train.shape)
print("transformed shape:", pca_data.shape)

plt.figure(figsize=(8,6))
plt.subplots_adjust(bottom = 0.1)
plt.figure(figsize=(12,8))
plt.subplots_adjust(bottom = 0.1)
scatter = plt.scatter(pca_data[:, 0], pca_data[:, 1], c= train_cluster_labels,label=train_cluster_labels,cmap=('rainbow'))
plt.xlabel("PCA1")
plt.ylabel("PCA2")
plt.title("Kmeans Clustering and feature dimension reduction (PCA) on Feature data",fontsize=14)
plt.legend(*scatter.legend_elements(), title="Clusters")
plt.show()

"""XGBoost Model"""

from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train,y_train)
xgb_pred = xgb.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score
xgb_acc = accuracy_score(y_test, xgb_pred )
xgb_prec = precision_score(y_test, xgb_pred )
xgb_recall = recall_score(y_test, xgb_pred )
xgb_roc = roc_auc_score(y_test, xgb_pred )
xgb_f1 = f1_score(y_test, xgb_pred )

print("Accuracy score:",xgb_acc)
print("Precision score:",xgb_prec)
print("Recall score:",xgb_recall)
print("F1-score:",xgb_f1)
print("AUC score:",xgb_roc)

#XGBoost hyper-parameter tuning
from sklearn.model_selection import GridSearchCV

xgb_model = XGBClassifier()
param_tuning = {
        'learning_rate': [0.01, 0.1],
        'max_depth': [3, 5, 7, 10],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.5, 0.7],
        'colsample_bytree': [0.5, 0.7],
        'n_estimators' : [100, 200, 500],
        'objective': ['reg:squarederror']
        }
grid_search = GridSearchCV(estimator = xgb_model,
                           param_grid = param_tuning,                        
                           #scoring = 'neg_mean_absolute_error', #MAE
                           #scoring = 'neg_mean_squared_error',  #MSE
                           cv = 5,
                           n_jobs = -1,
                           verbose = 1)
grid_search.fit(X_train,y_train)

xgb_best_model = grid_search.best_estimator_
pred_xgb = xgb_best_model.predict(X_test)
acc_xgb = accuracy_score(y_test, pred_xgb )
prec_xgb = precision_score(y_test, pred_xgb )
recall_xgb = recall_score(y_test, pred_xgb )
roc_xgb = roc_auc_score(y_test, pred_xgb )
f1_xgb = f1_score(y_test, pred_xgb )

print("Accuracy:",acc_xgb)
print("Precision:",prec_xgb)
print("Recalll:",recall_xgb)
print("F1-score:",f1_xgb)
print("AUC score:",roc_xgb)

# plot ROC curve

from sklearn import metrics
import matplotlib.pyplot as plt

fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_xgb)
def plot_roc_curve(fpr, tpr, label):
    plt.plot(fpr, tpr, linewidth=2, label=label)
    plt.plot([0,1],[0,1],"k--") #"k--" -> dashed line 
    plt.axis([0,1,0,1])
    plt.legend(title = "ROC curve",loc="lower right",fontsize = 20)
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    
plot_roc_curve(fpr, tpr,label = round(roc_xgb,2))
plt.title("ROC Curve for XGB Boosting");

"""Model Comparison

Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(penalty = 'l2', C = 1, random_state = 0)
lr.fit(X_train,y_train)
lr_pred = lr.predict(X_test)
lr_pred

lr_acc = accuracy_score(y_test, lr_pred )
lr_prec = precision_score(y_test, lr_pred )
lr_recall = recall_score(y_test, lr_pred )
lr_roc = roc_auc_score(y_test, lr_pred )
lr_f1 = f1_score(y_test, lr_pred )

print("Accuracy score:",lr_acc)
print("Precision score:",lr_prec)
print("Recall score:",lr_recall)
print("F1-score:",lr_f1)
print("AUC score:",lr_roc)

#1. Random Forest

from sklearn.ensemble import RandomForestClassifier
RF_model = RandomForestClassifier(random_state=42)
RF_model.fit(X_train,y_train)

RF_pred = RF_model.predict(X_test)
RF_acc = accuracy_score(y_test, RF_pred )
RF_prec = precision_score(y_test, RF_pred )
RF_recall = recall_score(y_test, RF_pred )
RF_roc = roc_auc_score(y_test, RF_pred )
RF_f1 = f1_score(y_test, RF_pred )

print("Accuracy score:",RF_acc)
print("Precision score:",RF_prec)
print("Recall score:",RF_recall)
print("F1-score:",RF_f1)
print("AUC score:",RF_roc)

#2. Support vector Machine

from sklearn.svm import SVC
svm_model = SVC()
svm_model.fit(X_train,y_train)
svm_model.predict(X_test)

svm_pred = svm_model.predict(X_test)
svm_acc = accuracy_score(y_test, svm_pred )
svm_prec = precision_score(y_test, svm_pred )
svm_recall = recall_score(y_test, svm_pred )
svm_roc = roc_auc_score(y_test, svm_pred )
svm_f1 = f1_score(y_test, svm_pred )

print("Accuracy score:",svm_acc)
print("Precision score:",svm_prec)
print("Recall score:",svm_recall)
print("F1-score:",svm_f1)
print("AUC score:",svm_roc)

#model comparison table

performance= [{'Methods': 'XGBoost', 'Accuracy': acc_xgb, 'Precision':prec_xgb,'Recall':recall_xgb,'F1-Score':f1_xgb,'AUC score':roc_xgb},
              {'Methods': 'Logistic Regression', 'Accuracy': lr_acc, 'Precision':lr_prec,'Recall':lr_recall,'F1-Score':lr_f1,'AUC score':lr_roc},  
              {'Methods': 'Support Vector Machine', 'Accuracy': svm_acc, 'Precision':svm_prec,'Recall':svm_recall,'F1-Score':svm_f1,'AUC score':svm_roc}, 
              {'Methods': 'Random Forest', 'Accuracy': RF_acc, 'Precision':RF_prec,'Recall':RF_recall,'F1-Score':RF_f1,'AUC score':RF_roc}
              ]
df_performance = pd.DataFrame(performance)
df_performance

#ROC Curve across all models
from sklearn.metrics import roc_curve

fpr1 , tpr1, thresholds1 = roc_curve(y_test, pred_xgb)
fpr2 , tpr2, thresholds2 = roc_curve(y_test, lr_pred)
fpr3 , tpr3, thresholds3 = roc_curve(y_test, RF_pred)
fpr4 , tpr4, thresholds4 = roc_curve(y_test, svm_pred)

plt.plot([0,1],[0,1], 'k--')
plt.plot(fpr1, tpr1, label= "xgb boosting")
plt.plot(fpr2, tpr2, label= "losgistic regression")
plt.plot(fpr3, tpr3, label= "random forest")
plt.plot(fpr4, tpr4, label= "Support vector Machine")
plt.legend()
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title('ROC-AUC of different models')
plt.show()

#1.correlation matrix between features and disease

cor = df_merge.corr(method='pearson')
cor

#plot correlation coefficient of features and variables
import matplotlib.pyplot as plt
import seaborn as sn

plt.figure(figsize=(16,8))
heatmap = sn.heatmap(cor,annot=True)
plt.xticks(range(df_merge.shape[1]), df_merge.columns, rotation=45)
plt.show()

#feature importance analysis
XGB = XGBClassifier(random_state=60)
XGB.fit(X_train,y_train)
XGB_importance = XGB.feature_importances_
indices = np.argsort(XGB_importance)

feature_imp = pd.Series(XGB.feature_importances_).sort_values(ascending=False)
feature_imp

plt.figure(figsize=(10,8))
plt.title("Feature importances from XGB Boost")
plt.barh(range(X_train.shape[1]), XGB_importance[indices],
       color="b",  align="center")
plt.yticks(range(X_train.shape[1]), df_merge.columns[0:-1])
plt.ylim([0,X_train.shape[1]])
plt.xticks()
plt.xlabel('Importance score'); 
plt.ylabel('Features'); 
plt.show()